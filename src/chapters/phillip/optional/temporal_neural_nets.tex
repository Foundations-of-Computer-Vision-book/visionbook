\newcommand{\xin}{\mathbf{x}_{\texttt{in}}}
\newcommand{\xout}{\mathbf{x}_{\texttt{out}}}
\newcommand{\xini}{x_{\texttt{in}_i}}
\newcommand{\xouti}{x_{\texttt{out}_i}}
\newcommand{\xink}{x_{\texttt{in}_k}}

\definecolor{param_color}{rgb}{0.2, 0.6, 1.0}
\definecolor{data_color}{rgb}{1.0, 0.4, 0.38}

\setcounter{chapter}{22}
\chapter{Temporal neural nets} 
[EARLY DRAFT -- INCOMPLETE]
\\

Visual signals often extend in time. For example videos. We need tools for modeling temporal sequences.

One big difference with spatial processing is that the time dimension is usually much bigger than the spatial dimensions of a video. Therefore we need tools that can handle very long sequences and model very long-range dependences between what happened at one point in time and what happens much later.

\Section{Temporal Convnets}


\Section{Recurrent Neural Networks}


\Section{Attention}


\Section{Transformers}

